{
  "name": "huggingface/cross-encoder/ms-marco-MiniLM-L-6-v2",
  "version": "1.0.2",
  "description": "The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order.",
  "model_format": "ONNX",
  "function_name": "TEXT_SIMILARITY",
  "model_task_type": "TEXT_SIMILARITY",
  "model_content_hash_value": "2fa5c50e6c5be452cc70de368e2ac78c85ca94cec41cf93e448bd022a506dadd",
  "model_config": {
    "model_type": "bert",
    "embedding_dimension": 384,
    "framework_type": "huggingface_transformers",
    "all_config": "{\n  \"_name_or_path\": \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 384,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 1536,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"sbert_ce_default_activation_function\": \"torch.nn.modules.linear.Identity\",\n  \"transformers_version\": \"4.22.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n"
  }
}
