{
  "name": "huggingface/sentence-transformers/multi-qa-MiniLM-L6-cos-v1",
  "version": "1.0.2",
  "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources.",
  "model_format": "ONNX",
  "model_task_type": "TEXT_EMBEDDING",
  "model_config": {
      "model_type": "bert",
      "embedding_dimension": 384,
      "framework_type": "sentence_transformers",
      "pooling_mode": "MEAN",
      "normalize_result": true,
      "all_config": "{\"_name_or_path\": \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\", \"architectures\": [\"BertModel\"], \"attention_probs_dropout_prob\": 0.1, \"classifier_dropout\": null, \"gradient_checkpointing\": false, \"hidden_act\": \"gelu\", \"hidden_dropout_prob\": 0.1, \"hidden_size\": 384, \"initializer_range\": 0.02, \"intermediate_size\": 1536, \"layer_norm_eps\": 1e-12, \"max_position_embeddings\": 512, \"model_type\": \"bert\", \"num_attention_heads\": 12, \"num_hidden_layers\": 6, \"pad_token_id\": 0, \"position_embedding_type\": \"absolute\", \"torch_dtype\": \"float32\", \"transformers_version\": \"4.49.0\", \"type_vocab_size\": 2, \"use_cache\": true, \"vocab_size\": 30522}",
      "additional_config": {
          "space_type": "l2"
      }
  },
  "model_content_size_in_bytes": 91719209,
  "model_content_hash_value": "732662a88c9fda2e74f5e68ec754d2523ded7feb042af217399a198ffcb16b10"
}